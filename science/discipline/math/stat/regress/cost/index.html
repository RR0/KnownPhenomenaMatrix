<!--#include virtual="/header-start.html" -->
<title>Fonction de coût</title>
<!--#include virtual="/header-end.html" -->
<p><i lang="en">cost function</i>) ou "fonction de perte" (<i class="en">loss function</i>).</p>
<section>
  <h2>Motivation</h2>
  <p>Déterminer la différence entre une modélisation et la réalité.</p>
</section>
<section>
  <h2>Analyse</h2>
  <p>On détermine une "fonction de coût" J comme suit :
  </p>
  <ol>
    <li>On définit une "<strong>erreur</strong>" ε de prédiction comme la différence entre une valeur prédite
      (`h_Θ^((x_i))` et une réelle (`y^((i))`) : `c(x) = h_Θ - y`</li>
    <li>Pour chacune des valeurs réelles (`i` de 1 à `m`), on calcule ces erreurs</li>
    <li>on prend la moyenne de ces erreurs en divisant par `m`</li>
  </ol>
  <p>`J = 1/m sum_(i=1)^m c(h_Θ, y)`</p>
  <p>où `c` est la fonction de coût partielle (en un `x`).</p>
</section>
<section>
  <h2>Exemples</h2>
  <p>Les fonctions de coût sont utilisées dans diverses méthodes de <a
      href="/science/discipline/math/stat/regress">régression statistique</a>.</p>
  <section>
    <h3>Régression linéaire ou non-linéaire</h3>
    <p>Pour calculer le coût lors d'une <a href="/science/discipline/math/stat/regress/linear">régression linéaire</a>
      ou <a href="/science/discipline/math/stat/regress/non-linear">non-linéaire</a>, comme les erreurs peuvent être
      positives ou négatives et que nous ne sommes intéressés que par l'écart/distance, on élève cette erreur au carré
      afin de le garantir toujours positif <span class="note">On pourrait théoriquement utiliser une fonction de valeur absolue à la place mais
        cela transformerait le résultat</span>. On annule/compense ensuite la mise au carré des erreurs en multipliant
      par 1/2 (ce qui annulera la dérivée de `x^2` qui est `2x`) :</p>
    <p>`c = 1/2 (h_Θ - y)^2`</p>
    <p>On parlera ici aussi de "fonction d'erreur carrée" (<i lang="en">squared error function</i>).</p>
  </section>
  <section>
    <h3>Régression logistique</h3>
    <p>Pour calculer le coût lors d'une <a href="/science/discipline/math/stat/regress/logistic">régression
      logistique</a>, on utilise le log :</p>
    <p>`c(h_θ(x),y)=−log(h_θ(x))` si `y = 1`<br/> `c(h_θ(x),y)=−log(1−h_θ(x))` si `y = 0`
    </p>
    <p>ce qui peut s'écrire en 1 seule ligne :</p>
    <p>`c(h_θ(x),y)=−y*log(h_θ(x))−(1−y)log(1−h_θ(x))`</p>
  </section>
  <section>
    <h3>Réseau de neurones</h3>
    <p>Pour calculer le coût pour un <a href="/tech/info/soft/data/science/ml/nn">réseau neuronal</a>, on
      généralise celui de la régression logistique non pas une seule sortie y mais K sorties :</p>
    <p>`J = 1/m sum_(i=1)^m sum_(k=1)^K c(h_Θ, y)`</p>
  </section>
</section>
<section>
  <h2>Notes</h2>
  <ul>
    <li>Attention, un coût nul ne signifie pas forcément que l'hypothèse est excellente. Cela peut plutôt paraître
      suspect et demande une vérification qu'il ne s'agit pas d'un cas d'<strong><em>overfitting</em></strong> (la
      fonction d'hypothèse couvre parfaitement les données connues mais ne correspondra probablement pas à de nouvelles
      données). Dans un tel cas, cette correspondance abusive peut être corrigée en :
      <ul>
        <li>réduisant le nombre de caractéristiques (n composantes de x) soit manuellement soit via un algorithme de
          sélection de modèle</li>
        <li><a href="../regul">régularisant</a> la magnitude des paramètres `θ_j` qui ne devraient avoir autant
          d'influence.
        </li>
      </ul>
    </li>
  </ul>
</section>
<!--#include virtual="/footer.html" -->
<style>.mjx-math * {
  line-height: 0;
}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=AM_CHTML"></script>
