<!--#include virtual="/header-start.html" -->
<title>M. L.</title>
<!--#include virtual="/header-end.html" -->
<p><i lang="en">Machine Learning</i> : apprentissage automatique.</p>
<section>
  <h2>Motivation</h2>
  <p>Extraire un modèle prédictif (<i lang="en">model fitting</i>) d'une <a href="..">analyse de données</a>.</p>
</section>
<section>
  <h2>Analyse</h2>
  <p>Le ML est un domaine de l'<a href="IA.html">IA</a> où un ensemble de données est utilisé pour "entraîner" :</p>
  <ul>
    <li>Apprentissage <strong>supervisé</strong> (<i lang="en">supervised learning</i>) : on indique à la machine ce
      qu'on attend d'elle, de manière à ce qu'elle produise une prédiction :
      <ul>
        <li><strong>quantitative</strong> : fonction continue issue d'une <a
            href="/science/discipline/math/stat/regress/linear">régression linéaire</a></li>
        <li><strong>qualitative</strong> : classification via <a href="/science/discipline/math/stat/regress/logistic">régression
          logistique</a></li>
        <li>les deux : déterminant une probabilité d'appartenir à une classe</li>
        <li><a href="svm">SVM</a></li>
        <li><a href="rf">Random Forest</a></li>
      </ul>
    </li>
    <li>Apprentissage <strong>non supervisé</strong> (<i lang="en">unsupervised learning</i>) : on demande à la machine
      de trouver elle-même des groupes (<i lang="en">clusters</i>) de données :
    <ul>
      <li><a href="kmeans">K-moyennes</a></li>
      </ul>
    </li>
  </ul>
</section>
<section>
  <h2>Conception</h2>
  <p>Il existe diverses techniques de ML mais on peut distinguer celles qui mobilisent une hiérarchie de "couches"
    d'apprentissage, qui constituent autant de niveau d'<a href="/tech/info/soft/proj/impl/lang/oo/Abstraction.html">abstraction</a>.
    On parlera alors d'<strong><a href="deep">apprentissage profond</a></strong> (<i lang="en">deep learning</i>).</p>
</section>
<section>
  <h2>Implémentation</h2>
  <p>Il peut bien sûr arriver qu'un algorithme d'apprentissage ne donne pas les résultats escomptés. On pourra alors
    opter pour différentes stratégies pour essayer de l'améliorer :</p>
  <table>
    <thead>
    <tr>
      <td class="titleCorner"></td>
      <th>Résoud l'<i lang="en"><a href="/science/discipline/math/stat/regress/underfit">underfitting</a> (high
        bias)</i></th>
      <th>Résoud l'<i lang="en"><a href="/science/discipline/math/stat/regress/overfit">overfitting</a> (high variance)</i>
      </th>
      <td>Commentaire</td>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>Entraîner l'algorithme sur <strong>plus de données</strong></td>
      <td class="non">Non</td>
      <td class="oui">Oui</td>
      <td>pour qu'il acquière une vision plus fine du problème</td>
    </tr>
    <tr>
      <td>Enlever des caractéristiques</td>
      <td class="non">Non</td>
      <td class="oui">Oui</td>
      <td>L'hypothèse est trop dépendante des données connues, elle pourrait ne pas bien prédire de nouvelles données
      </td>
    <tr>
    <tr>
      <td>Augmenter le facteur de <strong><a
          href="/science/discipline/math/stat/regress/regul">régularisation</a></strong></td>
      <td class="non">Non</td>
      <td class="oui">Oui</td>
      <td>La pénalisation de paramètres permet de moins coller aux données connues</td>
    </tr>
    <tr>
      <td>Diminuer le facteur de <strong><a
          href="/science/discipline/math/stat/regress/regul">régularisation</a></strong></td>
      <td class="oui">Oui</td>
      <td class="non">Non</td>
      <td>Ne pas trop pénaliser les paramètres permet de mieux prendre en compte les données connues</td>
    </tr>
    <tr>
      <td>Ajouter des caractéristiques</td>
      <td class="oui">Oui</td>
      <td class="non">Non</td>
      <td>L'hypothèse est trop simple. Des caractéristiques pourraient manquer à résoudre le problème</td>
    <tr>
    <tr>
      <td>Ajouter des <strong>caractéristiques polynomiales</strong> (`x_1^2, x_2^2, x_1x_2`, etc.) si c'est adapté à
        votre algorithme
      </td>
      <td class="oui">Oui</td>
      <td class="non">Non</td>
      <td>permettront de mieux cerner les hypothèses</td>
    </tr>
    </tbody>
  </table>
  <p>Cependant le travail nécessaire à ces améliorations peut se révéler long et il est recommandé de mener au préalable
    une analyse/un diagnostic aidant à sélectionner l'option la plus prometteuse. Ceci commence souvent par segmenter
    les données disponibles en ensembles de :</p>
  <ul>
    <li><strong>entraînement</strong> (<i lang="en">training set</i>) (60%, choisis aléatoirement si l'ordre est
      important) à partir duquel le modèle va apprendre (trouver ses paramètres optimaux) ;</li>
    <li><strong>test</strong> (<i lang="en">test set</i>) (20%, choisis aléatoirement si l'ordre est important) pour
      évaluer la performance de l'apprentissage sur des données qu'il n'a pas encore rencontrées ;</li>
    <li><strong>vérification</strong> (<i lang="en">cross-validation set</i>) (20%, choisis aléatoirement si l'ordre est
      important) pour trouver le paramétrage de <a
          href="/science/discipline/math/stat/regress/regul">régularisation </a> (on peut ainsi même automatiser cette
      recherche du meilleur taux de régularisation).
    </li>
  </ul>
  ce qui permet d'utiliser une fonction de <a href="/science/discipline/math/stat/regress/cost">calcul de coût</a>
  paramétrée pour un ensemble sur un autre ensemble. Il pourra aussi être utile de tracer les "courbes d'apprentissage"
  (<i lang="en">learning curves</i>) que représentent les erreurs (sans régularisation) des ensembles d'entraînement et
  de validation, en fonction de la taille de l'ensemble d'entraînement : ces courbes qui devraient converger peuvent en
  effet être indicatrices d'un <a href="/science/discipline/math/stat/regress/underfit"><i
    lang="en">underfitting</i></a> (biais élevé si la convergence s'effectue mais ne parvient pas à descendre d'un haut
  taux d'erreurs) ou <a
    href="/science/discipline/math/stat/regress/overfit"><i lang="en">overfitting</i></a> (variance élevée si les
  erreurs de l'ensemble de validation restent bien au-dessus de celles de l'ensemble d'entraînement).
</section>
<section>
  <h2>Voir</h2>
  <ul>
    <li>Framework
      <ul>
        <li><a href="https://js.tensorflow.org">TensorFlow.js</a></li>
      </ul>
    </li>
    <li>Cours (<abbr title="Massive Open Online Course">MOOC</abbr>s)
      <ul>
        <li><a href="https://www.kaggle.com/learn"><em>Kaggle</em></a></li>
        <li>Ng, Andrew: <a href="https://www.coursera.org/learn/machine-learning"><em>Machine Learning</em></a>,
          Université de Stanford, 2013</li>
        <li>Chaouche, Yannis: "<a
            href="https://openclassrooms.com/fr/courses/4011851-initiez-vous-au-machine-learning">Initiez-vous au
          machine learning</a>", OpenClassRooms, 2018</li>
        <li><a href="https://aws.amazon.com/fr/training/learning-paths/machine-learning">Machine Learning</a>, <abbr
            title="Amazon Web Services">AWS</abbr></li>
        <li><a href="https://developers.google.com/machine-learning">Cours d'initiation au Machine Learning avec les API
          TensorFlow</a>, Google</li>
      </ul>
    </li>
    <li>Compétitions
      <ul><li><a href="https://www.kaggle.com/competitions">Kaggle</a></li>
      </ul>
    </li>
  </ul>
</section>
<!--#include virtual="/footer.html" -->
<style>.mjx-math * {
  line-height: 0;
}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=AM_CHTML"></script>