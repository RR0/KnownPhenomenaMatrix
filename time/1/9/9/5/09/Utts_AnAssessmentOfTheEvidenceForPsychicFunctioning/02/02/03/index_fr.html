<!--#include virtual="/header-start.html" -->
<title>Aléatoirité et jugement par l'ordre</title>
<meta content="Utts, Jessica" name="author"/>
<meta content="Utts, Jessica" name="copyright"/>
<link href=".." rel="start" title="Une évaluation des éléments étayant le fonctionnement psi">
<link href=".." rel="contents" title="Définitions et questions statistiques">
<link href="../01" rel="prev" title="Définitions et procédures de recherche">
<link href="../03" rel="next" title="Questions méthodologiques">
<!--#include virtual="/header-end.html" -->
<p>À la base de toute méthode <a href="/science/discipline/hard/form/math/stat">statistique</a> il y a une définition de
  ce qui devrait arriver <q>aléatoirement</q> ou <q>par hasard</q>. Sans mécanisme aléatoire, il n'y a pas d'évaluation
  <a href="/science/discipline/hard/form/math/stat">statistique</a>.</p>
<p>Il n'y a rien d'aléatoire dans les réponses générées dans les expériences de cognition anomale ; en d'autres mots, il
  n'y a aucun moyen de définir à quoi elles devraient ressembler <a>au hasard</a>. Par conséquent, le mécanisme
  aléatoire de ces expériences doit être dans le choix de la cible. Ainsi, on peut comparer la réponse à la cible et
  répondre à la question : <q>S'il ne s'agit que de hasard, quelle est la probabilité que soit choisie une cible qui
    corresponde à cette réponse aussi bien ou mieux que la véritable cible ?</q></p>
<p>Afin de trouver cela, une expérience correctement menée utilise un ensemble de cibles définies à l'avance. Pour
  chaque <a href="/science/para/psi/pes/claivoyance/rv">vision à distance</a> une cible est choisie au hasard, de
  manière à ce que la probabilité de trouver chaque cible possible soit connue.</p>
<p>Les expériences de <a href="/science/para/psi/pes/claivoyance/rv">vision à distance</a> de la SAIC et toutes celles
  du <a href="/org/us/university/stanford/sri">SRI</a> sauf les premières ont utilisé la méthode d'évaluation
  statistique connue sous le nom de jugement par ordre de classement. Une fois la <a
      href="/science/para/psi/pes/claivoyance/rv">vision à distance</a> terminée, on montre à un juge qui ne connait pas
  la véritable cible (appelé juge aveugle) la réponse et 5 cibles potentielles, dont 1 est la réponse correcte et les 4
  autres des "leurres". Before the experiment is conducted each of those five choices must have had an equal chance of
  being selected as the actual target. The judge is asked to assign a rank to each of the possible targets, where a rank
  of one means it matches the response most closely, and a rank of five means it matches the least.</p>
<p>The rank of the correct target is the numerical score for that remote viewing. By chance alone the actual target
  would receive each of the five ranks with equal likelihood, since despite what the response said the target matching
  it best would have the same chance of selection as the one matching it second best and so on. The average rank by
  chance would be three. Evidence for anomalous cognition occurs when the average rank over a series of trials is
  significantly lower than three. (Notice that a rank of one is the best possible score for each viewing.)</p>
<p>This scoring method is conservative in the sense that it gives no extra credit for an excellent match. A response
  that describes the target almost perfectly will achieve the same rank of one as a response that contains only enough
  information to pick the target as the best choice out of the five possible choices. One advantage of this method is
  that it is still valid even if the viewer knows the set of possible targets. The probability of a first place match by
  chance would still be only one in five. This is important because the later SRI and many of the SAIC experiments used
  the same large set of National Geographic photographs as targets. Therefore, the experienced viewers would eventually
  become familiar with the range of possibilities since they were usually shown the answer at the end of each remote
  viewing session.</p>
<p>For technical reasons explained in Appendix 1, the effect size for a series of remote viewings using rank-order
  judging with five choices is (3.0 - average rank)/√2. Therefore, small, medium and large effect sizes (0.2, 0.5 and
  0.8) correspond to average ranks of 2.72, 2.29 and 1.87, respectively. Notice that the largest effect size possible
  using this method is 1.4, which would result if every remote viewing achieved a first place ranking.</p>
<!--#include virtual="/footer.html" -->
