<!--#include virtual="/header-start.html" -->
<title>Replication and Effect Sizes</title>
<meta content="Utts, Jessica" name="author"/>
<meta content="Utts, Jessica" name="copyright"/>
<link href=".." rel="start" title="An Assessment Of The Evidence For Psychic Functioning">
<link href=".." rel="contents" title="Statistical Issues and Definitions">
<link href="../01" rel="prev" title="Definitions and Research Procedures">
<link href="../03" rel="next" title="Methodological Issues">
<!--#include virtual="/header-end.html" -->
<p>In the past few decades scientists have realized that true replication of experimental results should focus on the
  magnitude of the effect, or the effect size rather than on replication of the p-value. This is because the latter is
  heavily dependent on the size of the study. In a very large study, it will take only a small magnitude effect to
  convincingly rule out chance. In a very small study, it would take a huge effect to convincingly rule out chance.</p>
<p>In our hypothetical sex-determination experiment, suppose 70 out of 100 births designed to be boys actually resulted
  in boys, for a rate of 70 percent instead of the 51 percent expected by chance. The experiment would have a p-value of
  0.0001, quite convincingly ruling out chance. Now suppose someone attempted to replicate the experiment with only ten
  births and found 7 boys, i.e also 70 percent. The smaller experiment would have a p-value of 0.19, and would not be
  statistically significant. If we were simply to focus on that issue, the result would appear to be a failure to
  replicate the original result, even though it achieved exactly the same 70 percent boys! In only ten births it would
  require 90 percent of them to be boys before chance could be ruled out. Yet the 70 percent rate is a more exact
  replication of the result than the 90 percent.</p>
<p>Therefore, while p-values should be used to assess the overall evidence for a phenomenon, they should not be used to
  define whether or not a replication of an experimental result was "successful." Instead, a successful replication
  should be one that achieves an effect that is within expected statistical variability of the original result, or that
  achieves an even stronger effect for explainable reasons.</p>
<p>A number of different effect size measures are in use in the social sciences, but in this report we will focus on the
  one used most often in remote viewing at SRI and SAIC. Because the definition is somewhat technical it is given in
  Appendix 1. An intuitive explanation will be given in the next subsection. Here, we note that an effect size of 0 is
  consistent with chance, and social scientists have, by convention, declared an effect size of 0.2 as small, 0.5 as
  medium and 0.8 as large. A medium effect size is supposed to be visible to the naked eye of a careful observer, while
  a large effect size is supposed to be evident to any observer.</p>
<!--#include virtual="/footer.html" -->
