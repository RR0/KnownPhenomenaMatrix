<!--#include virtual="/header-start.html" -->
<title>Experiment 10: Entropy II</title>
<meta content="Utts, Jessica" name="author"/>
<meta content="Utts, Jessica" name="copyright"/>
<link href="../01" rel="start" title="An Assessment Of The Evidence For Psychic Functioning">
<link href="../01" rel="contents" title="Experiments Involving Remote Viewing">
<link href=".." rel="prev" title="">
<link href="../01" rel="next" title="">
<!--#include virtual="/header-end.html" -->
<section>
  <h2>Purpose</h2>
  <p>This experiment was designed as an improved version of Experiment 1. After the unsuccessful showing for the dynamic
    targets in Experiment 1, the SAIC team speculated that the "target pool bandwidth" defined as the number of
    "cognitively differentiable elements" in the target pool might be an important factor. If the possible target
    material was extremely broad, viewers might have trouble filtering out extraneous noise. If the set of possibilities
    was too small, as in forced choice experiments, the viewer would see all choices at once and would have trouble
    filtering out that knowledge. An intermediate range of possibilities, too large to be considered all at once, was
    predicted to be ideal. The standard National Geographic pool seemed to fit that range. For this experiment, a pool
    of dynamic targets was created with a similar "band-width." In both Experiments (1 and 10) the researchers predicted
    that remote viewing success would correlate with the change in visual entropy of the target, as explained in Section
    4.6.1.</p>
</section>
<section>
  <h2>Method</h2>
  <p>Four of the five viewers from Experiment 1 were used (#s 009, 372, 389 and 518). They each contributed equal
    numbers of sessions with static and dynamic targets, with the viewers blind to which trials had which type. Senders
    were not used, and all sessions were conducted at SAIC in California, unlike Experiment 1 in which the viewers
    worked at home. Viewer #372 contributed 15 of each type while the others each contributed 10 of each type. Standard
    rank-order judging was used.</p>
</section>
<section>
  <h2>Results</h2>
  <p>Table 4 shows the results for this experiment. Unlike in Experiment 1, the static and dynamic targets produced
    identical effect sizes, with both types producing very successful results. The combined effect size for all trials
    is .55, resulting in a z-score of 5.22.</p>
  <table>
    <caption>TABLE 4: RESULTS FOR EXPERIMENT 10</caption>
    <thead>
    <tr>
      <th></th>
      <th colspan="3">Static Targets</th>
      <th colspan="3">Dynamic Targets</th>
    </tr>
    <tr>
      <th>Viewer</th>
      <th>Rank</th>
      <th>ES</th>
      <th><i>p</i></th>
      <th>Rank</th>
      <th>ES</th>
      <th><i>p</i></th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>009</td>
      <td>2.20</td>
      <td>.565</td>
      <td>.037</td>
      <td>1.70</td>
      <td>.919</td>
      <td>1.8×10<sup>-3</sup></td>
    </tr>
    <tr>
      <td>372</td>
      <td>1.87</td>
      <td>.801</td>
      <td>9.7×10<sup>-4</sup></td>
      <td>1.93</td>
      <td>.754</td>
      <td>1.8×10<sup>-3</sup></td>
    </tr>
    <tr>
      <td>389</td>
      <td>3.10</td>
      <td>-.071</td>
      <td>.589</td>
      <td>3.00</td>
      <td>.000</td>
      <td>.500</td>
    </tr>
    <tr>
      <td>518</td>
      <td>1.90</td>
      <td>.778</td>
      <td>7.2×10<sup>-3</sup></td>
      <td>2.40</td>
      <td>.424</td>
      <td>.091</td>
    </tr>
    <tr>
      <td>Total</td>
      <td>2.22</td>
      <td>.550</td>
      <td>1.1×10<sup>-5</sup></td>
      <td>2.22</td>
      <td>.550</td>
      <td>1.1×10<sup>-5</sup></td>
    </tr>
    </tbody>
  </table>
</section>
<!--#include virtual="/footer.html" -->
