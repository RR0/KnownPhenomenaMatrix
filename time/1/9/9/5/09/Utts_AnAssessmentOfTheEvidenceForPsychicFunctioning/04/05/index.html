<!--#include virtual="/header-start.html" -->
<title>Methodological Issues in the Remote Viewing Experiments at SAIC</title>
<meta content="Utts, Jessica" name="author"/>
<meta content="Utts, Jessica" name="copyright"/>
<link href=".." rel="contents" title="The SAIC Era">
<link href=".." rel="start" title="An Assessment Of The Evidence For Psychic Functioning">
<link href="../04" rel="prev" title="Consistency and Replicability of the Remote Viewing Results">
<link href="../06" rel="next" title="Was Anything Learned at SAIC?">
<!--#include virtual="/header-end.html" -->
<p>As noted in Section 2.3, there are a number of methodological considerations needed to perform a careful remote
  viewing experiment. Information necessary to determine how well each of these were addressed is generally available in
  the reports, but in some instances I consulted Dr. May for additional information. As an example of how the
  methodological issues in Section 2.3 were addressed, an explanation will be provided for Experiment 1.</p>
<p>In this experiment the viewers all worked from their homes (in New York, Kansas, California, and Virginia). Dr. Nevin
  Lantz, who resided in Pennsylvania, was the principal investigator. After each session, viewers faxed their response
  to Dr. Lantz and mailed the original to SAIC. Upon receipt of the fax, Dr. Lantz mailed the correct answer to the
  viewer. The viewers were supposed to mail their original responses to SAIC immediately, after faxing them to Dr.
  Lantz. According to Dr. May, the faxed versions were later compared with the originals to make sure the originals were
  sent without any changes. Here are how the other methodological issues in Section 2.3 were handled:</p>
<ul>
  <li><i>No one who has knowledge of the specific target should have any contact with the viewer until after the
    response has been safely secured.</i><br/>No one involved with the experiment had any contact with the viewers,
    since they were not in the vicinity of either SAIC or Dr. Lantz's home in Pennsylvania.</li>
  <li><i>No one who has knowledge of the specific target or even of whether or not the session was successful should
    have any contact with the judge until after that task has been completed.</i><br/>Dr. Lantz and the individual
    viewers were the only ones who knew the correct answers, but according to Dr. May, they did not have any contact
    with the judge during the period of this experiment.</li>
  <li><i>No one who has knowledge of the specific target should have access to the response until after the judging has
    been completed.</i><br/>Again, since only the viewers and Dr. Lantz knew the correct target, and since the responses
    were mailed to SAIC by the viewers before they received the answers, this condition appears to have been met.</li>
  <li><i>Targets and decoys used in judging should be selected using a well-tested randomization device.</i><br/>This
    has been standard practice at both SRI and SAIC.</li>
  <li><i>Duplicate sets of targets photographs should be used, one during the experiment and one during the judging, so
    that no cues (like fingerprints) can be inserted onto the target that would help the judge recognize it.</i><br/>This
    was done; Dr. Lantz maintained the set used during the experiment while the set used for judging was kept at SAIC in
    California.</li>
  <li><i>The criterion for stopping an experiment should be defined in advance so that it is not called to a halt when
    the results just happen to be favorable. Generally, that means specifying the number of trials in advance, but some
    statistical procedures require other stopping rules. The important point is that the rule be defined in advance in
    such a way that there is no ambiguity about when to stop.</i><br/>In advance it was decided that each viewer would
    contribute 40 trials, ten under each of four conditions (all combinations of sender/no sender and static/dynamic).
    All sessions were completed.</li>
  <li><i>Reasons, if any, for excluding data must be defined in advance and followed consistently, and should not be
    dependent on the data. For example, a rule specifying that a trial could be aborted if the viewer felt ill would be
    legitimate, but only if the trial was aborted before anyone involved in that decision knew the correct
    target.</i><br/> No such reasons were given, nor was there any mention of any sessions being aborted or discarded.
  </li>
  <li><i>Statistical analyses to be used must be planned in advance of collecting the data so that a method most
    favorable to the data isn't selected post hoc. If multiple methods of analysis are used the corresponding
    conclusions must recognize that fact.</i><br/>The standard rank-order judging had been planned, with results
    reported separately for each of the four conditions in the experiment for each viewer. Thus, 20 effect sizes were
    reported, four for each of the five viewers.</li>
</ul>
<!--#include virtual="/footer.html" -->
