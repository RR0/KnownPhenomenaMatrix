<!--#include virtual="/header-start.html" -->
<title>The SAIC Era</title>
<meta content="Utts, Jessica" name="author"/>
<meta content="Utts, Jessica" name="copyright"/>
<link href=".." rel="start" title="An Assessment Of The Evidence For Psychic Functioning">
<link href="../03" rel="prev" title="The SRI Era">
<link href="../05" rel="next" title="External validation: replications of other experiments">
<!--#include virtual="/header-end.html" -->
<section>
  <h3>An Overview</h3>
  <p>The review team decided to focus more intensively on the experiments conducted at <abbr title="Science Applications
    International Corporation">SAIC</abbr>, because they provide a manageable yet varied set to examine in detail. They
    were guided by a Scientific Oversight Committee consisting of experts in a variety of disciplines, including a
    winner of the Nobel Prize in Physics, internationally known professors of statistics, psychology, neuroscience and
    astronomy and a medical doctor who is a retired U.S. Army Major General. Further, we have access to the details for
    the full set of SAIC experiments, unlike for the set conducted at SRI. Whatever details may be missing from the
    written reports are obtainable from the principal investigator, Dr. Edwin May, to whom we have been given unlimited
    access.</p>
  <p>In a memorandum dated <time>1995-07-25</time>, Dr. Edwin May listed the set of experiments conducted by SAIC. There
    were ten experiments, all designed to answer questions about psychic functioning, raised by the work at SRI and
    other laboratories, rather than just to provide additional proof of its existence. Some of the experiments were of a
    similar format to the remote viewing experiments conducted at SRI and we can examine those to see whether or not
    they replicated the SRI results. We will also examine what new knowledge can be gained from the results of the SAIC
    work.</p>
</section>
<section>
  <h3>The Ten Experiments</h3>
  <p>Of the ten experiments done at SAIC, six of them involved remote viewing and four did not. Rather than list the
    details in the body of this report, Appendix 2 gives a brief description of the experiments. What follows is a
    discussion of the methodology and results for the experiments as a whole. Because of the fundamental differences
    between remote viewing and the other types of experiments, we discuss them separately.</p>
  <p>In the memorandum of 25 July 1995, Dr. May provided the review team with details of the ten experiments, including
    a short title, number of trials, effect size and overall p-value for each one. His list was in time sequence. It is
    reproduced in Table 1, using his numbering system, with the experiments categorized by type, then sequentially
    within type. The effect size estimates are based on a limited number of trials, so they are augmented with an
    interval to show the probable range of the true effect (e.g. .124±.071 indicates a range from .053 to .195).
    Remember that an effect size of 0 represents chance, while a positive effect size indicates positive results.</p>
  <table>
    <caption>TABLE 1: SAIC EXPERIMENTS LISTED BY DR. EDWIN MAY</caption>
    <thead>
    <tr>
      <th>Expr</th>
      <th>Title</th>
      <th>Trials</th>
      <th>Effect Size</th>
      <th><i>p-value</i></th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td colspan="5">Remote Viewing Experiments</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Target dependencies</td>
      <td>200</td>
      <td>.124±.071</td>
      <td>0.040</td>
    </tr>
    <tr>
      <td>4</td>
      <td>AC with binary coding</td>
      <td>40</td>
      <td>-.067±.158</td>
      <td>0.664</td>
    </tr>
    <tr>
      <td>5</td>
      <td>AC lucid dreams, base</td>
      <td>24</td>
      <td>.088±.204</td>
      <td>0.333</td>
    </tr>
    <tr>
      <td>6</td>
      <td>AC lucid dreams, pilot</td>
      <td>21</td>
      <td>.368±.218</td>
      <td>0.046</td>
    </tr>
    <tr>
      <td>9</td>
      <td>ERD AC Behavior</td>
      <td>70</td>
      <td>.303±.120</td>
      <td>0.006</td>
    </tr>
    <tr>
      <td>10</td>
      <td>Entropy II</td>
      <td>90</td>
      <td>.550±.105</td>
      <td>9.1×10-8</td>
    </tr>
    </tbody>
    <tr>
      <td colspan="5">Other Experiments</td>
    </tr>
    <tr>
      <td>2</td>
      <td>AC of binary targets</td>
      <td>300</td>
      <td>.123±.058</td>
      <td>0.017</td>
    </tr>
    <tr>
      <td>3</td>
      <td>MEG Replication</td>
      <td>12,000s</td>
      <td>MCE</td>
      <td>MCE</td>
    </tr>
    <tr>
      <td>7</td>
      <td>Remote observation</td>
      <td>48</td>
      <td>.361±.144</td>
      <td>0.006</td>
    </tr>
    <tr>
      <td>8</td>
      <td>ERD EEG investigation</td>
      <td>7,000s</td>
      <td>MCE</td>
      <td>MCE</td>
    </tr>
  </table>
</section>
<section>
  <h3>Assessing the Remote Viewing Experiments by Homogeneous Sets of Sessions</h3>
  <p>While Table 1 provides an overall assessment of the results of each experiment, it does so at the expense of
    information about variability among viewers and types of targets. In terms of understanding the phenomenon, it is
    important to break the results down into units that are as homogeneous as possible in terms of procedure, individual
    viewer and type of target. This is also important in order to assess the impact of any potential methodological
    problems. For example, in one pilot experiment (E6, AC in Lucid Dreams) viewers were permitted to take the targets
    home with them in sealed envelopes. Table 2 presents the effect size results at the most homogeneous level possible
    based on the information provided. For descriptions of the experiments, refer to Appendix 2. Overall effect sizes
    for each viewer and total effect sizes for each experiment are weighted according to the number of trials, so each
    trial receives equal weight.</p>
  <table>
    <caption>TABLE 2: INDIVIDUAL EFFECT SIZES</caption>
    <thead>
    <tr>
      <th>Experiment</th>
      <th colspan="5">Expert Remote Viewers</th>
      <th rowspan="2">Viewer Unknown/Other</th>
      <th>Total</th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td></td>
      <td>009</td>
      <td>131</td>
      <td>372</td>
      <td>389</td>
      <td>518</td>
    </tr>
    <tr>
      <td></td>
      <td colspan="6">Static Targets (National Geographics)</td>
      <td></td>
    </tr>
    <tr>
      <td>E1: Static</td>
      <td>.424</td>
      <td>-.071</td>
      <td>.424</td>
      <td>.177</td>
      <td>.283</td>
      <td>n.a.</td>
      <td>.247</td>
    </tr>
    <tr>
      <td>E9</td>
      <td>.432</td>
      <td>n.a.</td>
      <td>.354</td>
      <td>.177</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>.303</td>
    </tr>
    <tr>
      <td>E10: Static</td>
      <td>.566</td>
      <td>n.a.</td>
      <td>.801</td>
      <td>-.071</td>
      <td>.778</td>
      <td>n.a.</td>
      <td>.550</td>
    </tr>
    <tr>
      <td>E5 <span class="note">Experiment 5 did not include any expert viewers.</span></td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>.088</td>
      <td>.088</td>
    </tr>
    <tr>
      <td>E6 <span class="note">Experiment 6 included 4 expert viewers but separate results were not
provided.</span></td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>n.a.</td>
      <td>.370</td>
      <td>.370</td>
    </tr>
    <tr>
      <td>E4 <span
          class="note">Experiment 4 used a specially designed target set and only 4 choices in judging.</span>
      </td>
      <td>-.112</td>
      <td>n.a.</td>
      <td>0</td>
      <td>.112</td>
      <td>n.a.</td>
      <td>-.559</td>
      <td>-.067</td>
    </tr>
    <tr>
      <td></td>
      <td colspan="6">Dynamic Targets (Video Film Clips)</td>
    </tr>
    <tr>
      <td>E1: Dynamic</td>
      <td>0</td>
      <td>.354</td>
      <td>-.283</td>
      <td>0</td>
      <td>-.071</td>
      <td>n.a.</td>
      <td>.000</td>
    </tr>
    <tr>
      <td>E10: Dynamic</td>
      <td>.919</td>
      <td>n.a.</td>
      <td>.754</td>
      <td>0</td>
      <td>.424</td>
      <td>n.a.</td>
      <td>.550</td>
    </tr>
    <tr>
      <td>Overall</td>
      <td>.352</td>
      <td>.141</td>
      <td>.340</td>
      <td>.090</td>
      <td>.271</td>
      <td>n.a.</td>
    </tr>
    </tbody>
  </table>
</section>
<section>
  <h3>Consistency and Replicability of the Remote Viewing Results</h3>
  <p>One of the most important hallmarks of science is replicability. A phenomenon with statistical variability, whether
    it is scoring home runs in baseball, curing a disease with chemotherapy or observing psychic functioning, should
    exhibit about the same level of success in the long run, over repeated experiments of a similar nature. The remote
    viewing experiments are no exception. Remember that such events should not replicate with any degree of precision in
    the short run because of statistical variability, just as we would not expect to always get five heads and five
    tails if we flip a coin ten times, or see the same batting averages in every game.</p>
  <p>The analysis of SRI experiments conducted in 1988 singled out the laboratory remote viewing sessions performed by
    six "expert" remote viewers, numbers 002, 009, 131, 372, 414 and 504. These six individuals contributed 196
    sessions. The resulting effect size was 0.385 (May et al, 1988, p. 13). The SRI analysis does not include
    information individually by viewer, nor does it include information about how many of the 196 sessions used static
    versus dynamic targets. One report provided to the review team (May, Lantz and Piantineda, 1994) included an
    additional experiment conducted after the 1988 review was performed, in which Viewer 009 participated with 40
    sessions. The effect size for Viewer 009 for those sessions was .363. None of the other six SRI experts were
    participants.</p>
  <p>The same subject identifying numbers were used at SAIC, so we can compare the performance for these individuals at
    SRI and SAIC. Of the six, three were specifically mentioned as participating in the SAIC remote viewing experiments.
    As can be seen in Table 2, viewers 009, 131 and 372 all participated in Experiment 1 and viewers 009 and 372
    participated in Experiments 4, 9 and 10 as well.</p>
  <p>The overall effect sizes for two of the three, viewers 009 and 372, were very close to the SRI effect size of 0.385
    for these subjects, at .35 and .34, respectively, and the .35 effect size for Viewer 009 was very similar to his
    .363 effect size in the report by May, Lantz and Piantineda (1994). Therefore, we see a repeated and, more
    importantly, hopefully a repeatable level of functioning above chance for these individuals. An effect of this size
    should be reliable enough to be sustained in any properly conducted experiment with enough trials to obtain the long
    run statistical replicability required to rule out chance.</p>
  <p>It is also important to notice that viewers 009 and 372 did well on the same experiments and poorly on the same
    experiments. In fact the correlation between their effect sizes across experiments is .901, which is very close to a
    perfect correlation of 1.0. This kind of consistency warrants investigation to determine whether it is the nature of
    the experiments, a statistical fluke or some methodological problems that led these two individuals to perform so
    closely to one another. If methodological problems are responsible, then they must be subtle indeed because the
    methodology was similar for many of the experiments, yet the results were not. For instance, procedures for the
    sessions with static and dynamic targets in Experiment 1 were almost identical to each other, yet the dynamic
    targets did not produce evidence of psychic functioning (p-value = .50) and the static targets did (p-value =
    .0073). Therefore, a methodological problem would have had to differentially effect results for the two types of
    targets, even though the assignment of target type was random across sessions.</p></section>
<section>
  <h3>Methodological Issues in the Remote Viewing Experiments at SAIC</h3>
  <p>As noted in Section 2.3, there are a number of methodological considerations needed to perform a careful remote
    viewing experiment. Information necessary to determine how well each of these were addressed is generally available
    in the reports, but in some instances I consulted Dr. May for additional information. As an example of how the
    methodological issues in Section 2.3 were addressed, an explanation will be provided for Experiment 1.</p>
  <p>In this experiment the viewers all worked from their homes (in New York, Kansas, California, and Virginia). Dr.
    Nevin Lantz, who resided in Pennsylvania, was the principal investigator. After each session, viewers faxed their
    response to Dr. Lantz and mailed the original to SAIC. Upon receipt of the fax, Dr. Lantz mailed the correct answer
    to the viewer. The viewers were supposed to mail their original responses to SAIC immediately, after faxing them to
    Dr. Lantz. According to Dr. May, the faxed versions were later compared with the originals to make sure the
    originals were sent without any changes. Here are how the other methodological issues in Section 2.3 were
    handled:</p>
  <ul>
    <li><i>No one who has knowledge of the specific target should have any contact with the viewer until after the
      response has been safely secured.</i><br/>No one involved with the experiment had any contact with the viewers,
      since they were not in the vicinity of either SAIC or Dr. Lantz's home in Pennsylvania.</li>
    <li><i>No one who has knowledge of the specific target or even of whether or not the session was successful should
      have any contact with the judge until after that task has been completed.</i><br/>Dr. Lantz and the individual
      viewers were the only ones who knew the correct answers, but according to Dr. May, they did not have any contact
      with the judge during the period of this experiment.</li>
    <li><i>No one who has knowledge of the specific target should have access to the response until after the judging
      has been completed.</i><br/>Again, since only the viewers and Dr. Lantz knew the correct target, and since the
      responses were mailed to SAIC by the viewers before they received the answers, this condition appears to have been
      met.</li>
    <li><i>Targets and decoys used in judging should be selected using a well-tested randomization device.</i><br/>This
      has been standard practice at both SRI and SAIC.</li>
    <li><i>Duplicate sets of targets photographs should be used, one during the experiment and one during the judging,
      so that no cues (like fingerprints) can be inserted onto the target that would help the judge recognize
      it.</i><br/>This was done; Dr. Lantz maintained the set used during the experiment while the set used for judging
      was kept at SAIC in California.</li>
    <li><i>The criterion for stopping an experiment should be defined in advance so that it is not called to a halt when
      the results just happen to be favorable. Generally, that means specifying the number of trials in advance, but
      some statistical procedures require other stopping rules. The important point is that the rule be defined in
      advance in such a way that there is no ambiguity about when to stop.</i><br/>In advance it was decided that each
      viewer would contribute 40 trials, ten under each of four conditions (all combinations of sender/no sender and
      static/dynamic). All sessions were completed.</li>
    <li><i>Reasons, if any, for excluding data must be defined in advance and followed consistently, and should not be
      dependent on the data. For example, a rule specifying that a trial could be aborted if the viewer felt ill would
      be legitimate, but only if the trial was aborted before anyone involved in that decision knew the correct
      target.</i><br/> No such reasons were given, nor was there any mention of any sessions being aborted or discarded.
    </li>
    <li><i>Statistical analyses to be used must be planned in advance of collecting the data so that a method most
      favorable to the data isn't selected post hoc. If multiple methods of analysis are used the corresponding
      conclusions must recognize that fact.</i><br/>The standard rank-order judging had been planned, with results
      reported separately for each of the four conditions in the experiment for each viewer. Thus, 20 effect sizes were
      reported, four for each of the five viewers.</li>
  </ul>
</section>
<section>
  <h3>Was Anything Learned at SAIC?</h3>
  <section>
    <h4>Target Selection</h4>
    <p>In addition to the question of whether or not psychic functioning is possible, the experiments at SAIC were
      designed to explore a number of hypotheses. Experiments 1 and 10 were both designed to see if there is a
      relationship between the "change in visual entropy" in the targets and the remote viewing performance.</p>
    <p>Each of the five senses with which we are familiar is a change detector. Our vision is most readily drawn to
      something that is moving, and in fact if our eyes are kept completely still, we cease to see at all. Similarly, we
      hear because of moving air, and our attention is drawn to sudden changes in sound levels. Other senses behave
      similarly. Thus, it is reasonable that if there really is a "psychic sense" then it would follow that same
      pattern.</p>
    <p>Experiments 1 and 10 were designed to test whether or not remote viewing performance would be related to a
      particular type of change in the target material, namely the "change in visual entropy." A target with a high
      degree of change would be one in which the colors changed considerably throughout the target. A detailed
      explanation can be found in the SAIC reports of this experiment, or in the article "Shannon Entropy: A Possible
      Intrinsic Target Property" by May, Spottiswoode and James, in the Journal of Parapsychology, December 1994. It was
      indeed found that there was a correlation between the change in entropy in the target and the remote viewing
      quality. This result was initially shown in Experiment 1 and replicated in Experiment 10. A simulation study
      matching randomly chosen targets to responses showed that this was unlikely to be an artifact of target complexity
      or other features.</p>
    <p>It is worth speculating on what this might mean for determining how psychic functioning works. Physicists are
      currently grappling with the concept of time, and cannot rule out precognition as being consistent with current
      understanding. Perhaps it is the case that we do have a psychic sense, much like our other senses, and that it
      works by scanning the future for possibilities of major change much as our eyes scan the environment for visual
      change and our ears are responsive to auditory change. That idea is consistent with anecdotal reports of
      precognition, which are generally concerned with events involving major life change. Laboratory remote viewing may
      in part work by someone directing the viewer to focus on a particular point in the future, that in which he or she
      receives the feedback from the experiment. It may also be the case that this same sense can scan the environment
      in actual time and detect change as well.</p>
    <p>Another hypothesis put forth at SAIC was that laboratory remote viewing experiments are most likely to be
      successful if the pool of potential targets is neither too narrow nor too wide in terms of the number of possible
      elements in the target. They called this feature the "target- pool bandwidth" and described it as the number of
      "differentiable cognitive elements." They reasoned that if the possible target set was too small, the viewer would
      see the entire set and be unable to distinguish that information from the psychic information. If the set was too
      broad, the viewer would not have any means for editing an extensive imagination.</p>
    <p>Combining these two results would indicate that a good target set would contain targets with high change in
      visual entropy, but that the set would contain a moderately-sized set of possibilities. The set of 100 National
      Geographic photographs used in the later days at SRI and at SAIC may have inadvertently displayed just those
      properties.</p>
  </section>
  <section>
    <h4>Remote Staring</h4>
    <p>Experiment 7, described in Appendix 2, provided results very different from the standard remote viewing work.
      That experiment was designed to test claims made in the Former Soviet Union and by some researchers in the United
      States, that individuals could influence the physiology of another individual from a remote location. The study
      was actually two separate replications of the same experiment, and both replications were successful from a
      traditional statistical perspective. In other words, it appeared that the physiology of one individual was
      activated when he or she was being watched by someone in a distant room. If these results are indeed sound, then
      they may substantiate the folklore indicating that people know when they are being observed from behind.</p>
  </section>
  <section>
    <h4>Enhanced Binary Computer Guessing</h4>
    <p>Experiment 2 was also very different from the standard remote viewing experiments, although it was still designed
      to test anomalous cognition. Three subjects attempted to use a statistical enhancement technique to increase the
      ability to guess forced choice targets with two choices. This clever computer experiment showed that for one
      subject, guessing was indeed enhanced from a raw rate of just above chance (51.6% instead of 50%) to an enhanced
      rate of 76 percent. The method was extremely inefficient, and it is difficult to imagine practical uses for this
      ability, if indeed it exists.</p></section>
</section>
<!--#include virtual="/footer.html" -->
